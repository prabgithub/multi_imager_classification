{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16b2873-5fec-431b-b00a-7188364a99b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step-1 Notebook for processing raw flowcam data, visualising no. of samples vs flowcam phytoplankton categories and visualising common categories between Flowcam and IFCB datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7478fed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import sys\n",
    "from os import listdir, path\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a77dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2c8e3d-9299-4b00-adc2-894be8211c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01898afe-866a-46de-b066-e94ed50d085e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in os.listdir(\"./\"):\n",
    "#     if os.path.isdir(i):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff183f61-5416-4320-b215-76f8f436d9c4",
   "metadata": {},
   "source": [
    "## Defining the function process_flowcam which parses the raw flowcam files and stores them in \"flocam_processed_1\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5789d5-254a-40e0-a133-9fac96a82871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_flowcam(fc_dir,target_dir,resize= False):\n",
    "    images_list=[]\n",
    "    flb_path = fc_dir + \"/*.flb\"\n",
    "    # make the individual category directory \n",
    "    for i in tqdm(glob.glob(flb_path),leave=True):\n",
    "        dir_name=i.split('.')[1].split('/')[2].strip()\n",
    "        dir_path_obj=Path(f'{target_dir}/{dir_name}')\n",
    "        if not dir_path_obj.exists():\n",
    "            # Create the directory (including any necessary parent directories)\n",
    "            dir_path_obj.mkdir(parents=True, exist_ok=True)\n",
    "            try:\n",
    "                with open(i,'r') as fh:\n",
    "                    data=fh.readlines()\n",
    "                col_names=[]\n",
    "                col_values=[]\n",
    "                for j in data[2:]:\n",
    "                    if j.count('|')==1:\n",
    "                        a=j.split('|')[0]\n",
    "                        col_names.append(a)\n",
    "                    else:\n",
    "                        b=j.split('|')\n",
    "                        col_values.append(b)\n",
    "\n",
    "                data_pd=pd.DataFrame(col_values,columns=col_names)\n",
    "                # Print the current progress\n",
    "                print(f\"{dir_name} processed {data_pd.shape[:2]}\")\n",
    "                images_list.append(f\"{dir_name} {data_pd.shape[:2]}\")\n",
    "            except Exception as e:\n",
    "                print(f'error occured in dataframe creation {e}')\n",
    "\n",
    "        #images parsing from the above dataframe\n",
    "            images_data: List = []\n",
    "            try:\n",
    "                for index, row in data_pd.iterrows():\n",
    "                    image_collage_path = path.join(\n",
    "                        fc_dir, row['collage_file'])\n",
    "                    im = cv2.imread(image_collage_path)\n",
    "                    # Clipping the corresponding image from collage file\n",
    "                    im = im[\n",
    "                        int(row['image_y']):int(row['image_y'])+int(row['image_h']),\n",
    "                        int(row['image_x']):int(row['image_x'])+int(row['image_w'])]\n",
    "                    if resize:\n",
    "                        # transform images to portrait orientation\n",
    "                        # if width > height\n",
    "                        (h, w) = im.shape[:2]\n",
    "                        if w > h:\n",
    "                            im = cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)\n",
    "                        im = cv2.resize(im, desired_image_size)\n",
    "                    # normalize the image pixel values between 0 to 255 \n",
    "                    im = im / 255\n",
    "                    images_data.append(im)\n",
    "                images_data: np.array = np.array(images_data, dtype=object)\n",
    "            except Exception as e:\n",
    "                print(f\"error in image_creation {dir_name}_{e}\")\n",
    "\n",
    "        #save the data\n",
    "            try:\n",
    "                data_pd.to_csv(f'{target_dir}/{dir_name}/{dir_name}_pd.csv',index=False)\n",
    "                np.save(f'{target_dir}/{dir_name}/{dir_name}_im.npy',images_data)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"error in storing data {e}\")\n",
    "        else:\n",
    "            print(f\"Directory {dir_path_obj} already exists. Skipping data creation.\")\n",
    "            pass\n",
    "    return images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413565a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euterpina_copepod processed (44, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:02<00:08,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eutintinnus_tintinnid processed (58, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:03<00:03,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Echinoderm_larvae processed (16, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty_lorica processed (46, 65)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "fc_dir=\"./raw_flowcam_data\"\n",
    "target_dir=\"./flowcam_processed_1\"\n",
    "images_list=process_flowcam(fc_dir,target_dir,resize= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e252420-2442-4ef0-a939-18aebc8cc0f9",
   "metadata": {},
   "source": [
    "### Resizing and merging all the phytoplankton data into single dataframe and numpy objects and saving to \"flowcam_merged_data\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "362969ce-0881-4ebc-8eb0-9a548fc7f930",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 66)\n",
      "44\n",
      "unique--> [0]\n",
      "resized_shape--> (44, 101, 64, 3)\n",
      "******************** Euterpina_copepod idx--> 0 ********************\n",
      "(46, 66)\n",
      "46\n",
      "unique--> [1]\n",
      "resized_shape--> (46, 101, 64, 3)\n",
      "******************** Empty_lorica idx--> 1 ********************\n",
      "(16, 66)\n",
      "16\n",
      "unique--> [2]\n",
      "resized_shape--> (16, 101, 64, 3)\n",
      "******************** Echinoderm_larvae idx--> 2 ********************\n",
      "(58, 66)\n",
      "58\n",
      "unique--> [3]\n",
      "resized_shape--> (58, 101, 64, 3)\n",
      "******************** Eutintinnus_tintinnid idx--> 3 ********************\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "class_dict: defaultdict = defaultdict(dict)\n",
    "dataframes: List = []\n",
    "all_images: List = []\n",
    "desired_image_size = (64,101)\n",
    "\n",
    "for idx, directory in enumerate(glob.glob(\"./flowcam_processed_1/*\")):\n",
    "    resized_images=[]\n",
    "    # our class_dict will save human readable name to integer key\n",
    "    class_dict[idx] = os.path.basename(directory)\n",
    "    # read the df and add target variable equal to idx\n",
    "    df = pd.read_csv(glob.glob(path.join(directory,\"*.csv\"))[0])\n",
    "    df[\"_target\"]=idx\n",
    "    print(df.shape)\n",
    "    # resize all images to same size that corrospond to each row in df above.\n",
    "    images = np.load(glob.glob(path.join(directory,\"*.npy\"))[0],allow_pickle=True)\n",
    "    for im in images:\n",
    "        (h, w) = im.shape[:2]\n",
    "        if w > h:\n",
    "            im = cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)\n",
    "            im = cv2.resize(im, desired_image_size)\n",
    "        else:\n",
    "            im = cv2.resize(im, desired_image_size)\n",
    "        resized_images.append(im)\n",
    "        \n",
    "    print(len(resized_images))\n",
    "    dataframes.append(df)\n",
    "    len_res = len(resized_images)\n",
    "    resized_images=np.array(resized_images)\n",
    "    all_images.append(resized_images)\n",
    "    if df.shape[0]==len_res:\n",
    "        print('unique-->',np.unique(df[\"_target\"]))\n",
    "        print('resized_shape-->',resized_images.shape)\n",
    "        print('*'*20,os.path.basename(directory),'idx-->',idx,'*'*20)\n",
    "    else:\n",
    "        print('failed',idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e50bc00-d572-43f3-a73a-35d26cf621b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge all the dataframe and images into single dataframe and numpy object respectively\n",
    "path_to_merged = './flowcam_merged_data/'\n",
    "os.makedirs('./flowcam_merged_data/',exist_ok=True)\n",
    "df: pd.DataFrame = pd.concat(dataframes, sort=True)\n",
    "df.to_csv(path.join(path_to_merged, 'merged_df.csv'))\n",
    "\n",
    "all_images: np.array = np.vstack(all_images)\n",
    "np.save(path.join(path_to_merged, 'merged_images.npy'),all_images)\n",
    "np.save(path.join(path_to_merged,'class_dict.npy'),class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a531db-9333-40ba-bae3-49c64fe4737a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./flowcam_merged_data/merged_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d517080-e96e-4a09-a9dc-99e738f9ced3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_images=np.load(\"./flowcam_merged_data/merged_images.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68ec2a12-293e-41a9-ac58-01eea0277876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_dict=np.load(\"./flowcam_merged_data/class_dict.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23b97567-5d9b-484d-b0a3-6defc22ffe8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((164, 67), (164, 101, 64, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aba86b65-87ad-48a3-8ef6-1a1d4b4dacf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', '_target', 'abd_area', 'abd_diameter', 'avg_blue',\n",
       "       'avg_green', 'avg_red', 'cal_const', 'cal_image', 'camera', 'ch1_area',\n",
       "       'ch1_peak', 'ch1_width', 'ch2_area', 'ch2_peak', 'ch2_width',\n",
       "       'ch3_area', 'ch3_peak', 'ch3_width', 'circle_fit', 'circularity_hu',\n",
       "       'collage_file', 'compactness', 'convex_perimeter', 'edge_gradient',\n",
       "       'elapsed_time', 'elongation', 'esd_diameter', 'fd_diameter',\n",
       "       'feret_max_angle', 'feret_min_angle', 'filled_area', 'fringe_size',\n",
       "       'id', 'image_h', 'image_id', 'image_w', 'image_x', 'image_y',\n",
       "       'intensity', 'intensity_calimage', 'length', 'perimeter', 'ppc',\n",
       "       'raw_area', 'raw_convex_hull_area', 'raw_convex_perimeter',\n",
       "       'raw_feret_max', 'raw_feret_mean', 'raw_feret_min', 'raw_filled_area',\n",
       "       'raw_legendre_major', 'raw_legendre_minor', 'raw_perimeter',\n",
       "       'raw_sphere_complement', 'raw_sphere_unknown', 'raw_sphere_volume',\n",
       "       'roughness', 'sigma_intensity', 'sphere_count', 'src_image', 'src_x',\n",
       "       'src_y', 'sum_intensity', 'symmetry', 'timestamp', 'width'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22466d2-4f84-4df7-b266-77223f43c365",
   "metadata": {},
   "source": [
    "### feature engineering and splitting the merged data into traning, validation amd test data and saving to \"flowcam_split_data\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fba9084-e03d-4dda-8bd0-1841fa38e598",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total columns after modifying df -- 44\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import (drop_columns, prepare_training_data, process_attributes)\n",
    "df: pd.DataFrame = df.drop(['Unnamed: 0'],axis=1)\n",
    "df = process_attributes(df)\n",
    "# drop features that are no longer needed for training\n",
    "df = drop_columns(df)\n",
    "\n",
    "print(f'total columns after modifying df -- {len(df.columns)}')\n",
    "\n",
    "min_samples=14\n",
    "\n",
    "''' a custom standard scaler is called from utils inside prepare_training_data and \n",
    "    rescaler is stored at path below using joblib.dumb'''\n",
    "'''dump(rescaler, './flowcam_split_data/std_scaler.bin', compress=True)'''\n",
    "\n",
    "path_to_store_std_scaler = './flowcam_split_data/std_scaler.bin'\n",
    "os.makedirs('./flowcam_split_data/', exist_ok= True)\n",
    "\n",
    "trainAttrX, valAttrX, testAttrX, trainImagesX, \\\n",
    "    valImagesX, testImagesX, y_train, y_val, y_test = \\\n",
    "    prepare_training_data(df, all_images, min_samples, path_to_store_std_scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7f72933-a118-49a3-a3f2-e64f637ff06a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118, 43),\n",
       " (23, 43),\n",
       " (23, 43),\n",
       " (118, 101, 64, 3),\n",
       " (23, 101, 64, 3),\n",
       " (23, 101, 64, 3),\n",
       " (118, 4),\n",
       " (23, 4),\n",
       " (23, 4))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAttrX.shape, valAttrX.shape, testAttrX.shape, trainImagesX.shape, \\\n",
    "    valImagesX.shape, testImagesX.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93d28553-21b2-47f4-8292-e16d36a431ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the class dictionary, for later use,\n",
    "np.save(path.join('./flowcam_split_data', 'class_dict.npy'),\n",
    "        class_dict,allow_pickle=True)\n",
    "\n",
    "processed_training_data_path=path.join(\"./flowcam_split_data\", \"plankton_data_101x64_final.pkl\")\n",
    "# finally save the training data for future use\n",
    "with open(processed_training_data_path, \"wb\") as f:\n",
    "    pickle.dump((trainAttrX, valAttrX, testAttrX, trainImagesX,\n",
    "                 valImagesX, testImagesX, y_train, y_val, y_test),\n",
    "                f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbd499d-44d4-402c-af43-29eab70da436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flowcam  Env",
   "language": "python",
   "name": "flwcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
