{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8904245f-5bc7-4077-a1ce-e926422ef816",
   "metadata": {},
   "source": [
    "# Step-2 Notebook for processing raw IFCB data, and adding 5 features viz. height, width and average channel colors as feature data corresponding to each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7478fed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import sys\n",
    "from os import listdir, path\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db28a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/conda/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f9943a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lustre_scratch/prabgithub/test_folder/project_code1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a77dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4c9d97-6d38-4077-a8bb-11d4a9ccea8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./raw_ifcb_data/ --> 0\n"
     ]
    }
   ],
   "source": [
    "for rt,dr,fl in os.walk('./raw_ifcb_data/',topdown=True):\n",
    "    if not fl:\n",
    "        print(rt,'-->',len(fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c03d47d-2e78-408a-b858-1cb8ad9e14d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acantharian\n",
      "Alexandrium\n",
      "Acanthoica_quattrospina\n",
      "Amphorelloides_tropidoneis\n",
      "Amphidinium_crassipes\n",
      "Askenasia\n",
      "Asterompalus_flabellatus\n"
     ]
    }
   ],
   "source": [
    "for i in glob.glob(\"./raw_ifcb_data/*\"):\n",
    "    print(os.path.basename(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00cfb54f-2586-4fab-b6ed-96165f2bbd56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ifcb_cat=[]\n",
    "for i in glob.glob(\"./raw_ifcb_data/*\"):\n",
    "    if os.path.isdir(i) and (os.path.basename(i) != '.ipynb_checkpoints') :\n",
    "        if len(os.listdir(i))==0:\n",
    "            print('empty folder -->',i)\n",
    "        else: \n",
    "            # print(i,'filled folder')\n",
    "            ifcb_cat.append(os.path.basename(i))\n",
    "    else: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdcc0ffc-a12e-4c79-a0dc-c86da60977cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acantharian',\n",
       " 'Alexandrium',\n",
       " 'Acanthoica_quattrospina',\n",
       " 'Amphorelloides_tropidoneis',\n",
       " 'Amphidinium_crassipes',\n",
       " 'Askenasia',\n",
       " 'Asterompalus_flabellatus']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ifcb_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442aa8cb-0ee0-4248-9b73-654f0562b462",
   "metadata": {},
   "source": [
    "### Feature extraction and stroing images data as numpy database in corresponding phytoplankton directory in \"ifcb_processed_1\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e72b600-3013-4962-b524-88ae8c88c89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_ifcb_images_folder='./ifcb_processed_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cddd4187-bfe4-4cb4-af31-f7159373767d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (2, 5)\n",
      "processed_Acantharian with target_id_0\n",
      "****************************************\n",
      "59 (59, 5)\n",
      "processed_Acanthoica_quattrospina with target_id_1\n",
      "****************************************\n",
      "21 (21, 5)\n",
      "processed_Alexandrium with target_id_2\n",
      "****************************************\n",
      "4 (4, 5)\n",
      "processed_Amphidinium_crassipes with target_id_3\n",
      "****************************************\n",
      "62 (62, 5)\n",
      "processed_Amphorelloides_tropidoneis with target_id_4\n",
      "****************************************\n",
      "10 (10, 5)\n",
      "processed_Askenasia with target_id_5\n",
      "****************************************\n",
      "2 (2, 5)\n",
      "processed_Asterompalus_flabellatus with target_id_6\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "for m,i in enumerate(np.sort(ifcb_cat)):\n",
    "    df = pd.DataFrame(columns=['height','width','B','G','R'])\n",
    "    images_data=[]\n",
    "    os.makedirs(os.path.join(processed_ifcb_images_folder,f'./{i}'),exist_ok=True)\n",
    "    save_path=os.path.join(processed_ifcb_images_folder,f'./{i}')\n",
    "    for k,j in enumerate(glob.glob(f'./raw_ifcb_data/{i}/*')):\n",
    "        try:\n",
    "            img=cv2.imread(j)\n",
    "            img=img/255\n",
    "            mean_color = cv2.mean(img)\n",
    "            # mean_color is a tuple of the form (B, G, R, A)\n",
    "            # If the image has no alpha channel, the A value will be 0\n",
    "            average_color = mean_color[:3] \n",
    "            df.loc[k,['height','width']]=img.shape[:2]\n",
    "            df.loc[k,['B','G','R']]=average_color\n",
    "            images_data.append(img)\n",
    "        except Exception as e:\n",
    "            print(f'problem with_{k}_of_{j}_of_{i}_error_{e}')\n",
    "            print('#'*40)\n",
    "    try:\n",
    "        images_data_object = np.empty(len(images_data), dtype=object)\n",
    "        for l in range(len(images_data)):\n",
    "            images_data_object[l] = images_data[l]\n",
    "        np.save(os.path.join(save_path,f'{i}.npy'),images_data_object)\n",
    "        # df['_target']=m\n",
    "        print(len(images_data),df.shape)\n",
    "        df.to_csv(os.path.join(save_path,f'{i}.csv'),index=False)\n",
    "        print(f'processed_{i} with target_id_{m}')\n",
    "        print('*'*40)\n",
    "    except Exception as e:\n",
    "            print(f'problem with_{k}_of_{j}_of_{i}_error_{e}')\n",
    "            print('#'*40)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870928f7-8c27-4476-9ff6-0cca6b2bff80",
   "metadata": {},
   "source": [
    "### Resizing and merging all the phytoplankton data into single dataframe and numpy objects and saving to \"ifcb_merged_data\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42fe66fa-ee9e-44e3-bce8-d9424f226cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6)\n",
      "2\n",
      "unique--> [0]\n",
      "resized_shape--> (2, 101, 64, 3)\n",
      "******************** Acantharian idx--> 0 ********************\n",
      "(21, 6)\n",
      "21\n",
      "unique--> [1]\n",
      "resized_shape--> (21, 101, 64, 3)\n",
      "******************** Alexandrium idx--> 1 ********************\n",
      "(59, 6)\n",
      "59\n",
      "unique--> [2]\n",
      "resized_shape--> (59, 101, 64, 3)\n",
      "******************** Acanthoica_quattrospina idx--> 2 ********************\n",
      "(62, 6)\n",
      "62\n",
      "unique--> [3]\n",
      "resized_shape--> (62, 101, 64, 3)\n",
      "******************** Amphorelloides_tropidoneis idx--> 3 ********************\n",
      "(4, 6)\n",
      "4\n",
      "unique--> [4]\n",
      "resized_shape--> (4, 101, 64, 3)\n",
      "******************** Amphidinium_crassipes idx--> 4 ********************\n",
      "(10, 6)\n",
      "10\n",
      "unique--> [5]\n",
      "resized_shape--> (10, 101, 64, 3)\n",
      "******************** Askenasia idx--> 5 ********************\n",
      "(2, 6)\n",
      "2\n",
      "unique--> [6]\n",
      "resized_shape--> (2, 101, 64, 3)\n",
      "******************** Asterompalus_flabellatus idx--> 6 ********************\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "class_dict: defaultdict = defaultdict(dict)\n",
    "dataframes: List = []\n",
    "all_images: List = []\n",
    "desired_image_size = (64,101)\n",
    "\n",
    "for idx, directory in enumerate(glob.glob(\"./ifcb_processed_1/*\")):\n",
    "    resized_images=[]\n",
    "    # our class_dict will save human readable name to integer key\n",
    "    class_dict[idx] = os.path.basename(directory)\n",
    "    # read the df and add target variable equal to idx\n",
    "    df = pd.read_csv(glob.glob(path.join(directory,\"*.csv\"))[0])\n",
    "    df[\"_target\"]=idx\n",
    "    print(df.shape)\n",
    "    # resize all images to same size that corrospond to each row in df above.\n",
    "    images = np.load(glob.glob(path.join(directory,\"*.npy\"))[0],allow_pickle=True)\n",
    "    for im in images:\n",
    "        (h, w) = im.shape[:2]\n",
    "        if w > h:\n",
    "            im = cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)\n",
    "            im = cv2.resize(im, desired_image_size)\n",
    "        else:\n",
    "            im = cv2.resize(im, desired_image_size)\n",
    "        resized_images.append(im)\n",
    "        \n",
    "    print(len(resized_images))\n",
    "    dataframes.append(df)\n",
    "    len_res = len(resized_images)\n",
    "    resized_images=np.array(resized_images)\n",
    "    all_images.append(resized_images)\n",
    "    if df.shape[0]==len_res:\n",
    "        print('unique-->',np.unique(df[\"_target\"]))\n",
    "        print('resized_shape-->',resized_images.shape)\n",
    "        print('*'*20,os.path.basename(directory),'idx-->',idx,'*'*20)\n",
    "    else:\n",
    "        print('failed',idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd86e412-721f-437d-82b4-2b5b3c11bac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge all the dataframe and images into single dataframe and numpy object respectively\n",
    "path_to_merged = './ifcb_merged_data/'\n",
    "os.makedirs('./ifcb_merged_data/',exist_ok=True)\n",
    "df: pd.DataFrame = pd.concat(dataframes, sort=True)\n",
    "df.to_csv(path.join(path_to_merged, 'merged_df.csv'))\n",
    "\n",
    "all_images: np.array = np.vstack(all_images)\n",
    "np.save(path.join(path_to_merged, 'merged_images.npy'),all_images)\n",
    "np.save(path.join(path_to_merged,'class_dict.npy'),class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d027cf-0520-4ee2-8c5e-ca844584fcd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./ifcb_merged_data/merged_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccbb02f0-8119-44ba-83c6-c6a22d7bbaed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_images=np.load(\"./ifcb_merged_data/merged_images.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e03082db-39a1-4957-9bf1-4d9dbfa9dcf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_dict=np.load(\"./ifcb_merged_data/class_dict.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfb35b8f-e15e-481e-949b-f38ed9f75399",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 7), (160, 101, 64, 3))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf0b64d6-e0a3-43b5-80a1-66617290aa84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'B', 'G', 'R', '_target', 'height', 'width'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000b44d8-e445-4b48-b7f9-fe676877718e",
   "metadata": {},
   "source": [
    "### splitting the merged data into traning, validation amd test data and saving to \"ifcb_split_data\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9230caf-c5a6-4028-837e-1097d6aca692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total columns after modifying df -- 6\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import prepare_training_data\n",
    "\n",
    "df: pd.DataFrame = df.drop(['Unnamed: 0'],axis=1)\n",
    "# drop features that are no longer needed for training\n",
    "print(f'total columns after modifying df -- {len(df.columns)}')\n",
    "\n",
    "min_samples=10\n",
    "\n",
    "''' a custom standard scaler is called from utils inside prepare_training_data and \n",
    "    rescaler is stored at path below using joblib.dumb'''\n",
    "'''dump(rescaler, './ifcb_split_data/std_scaler.bin', compress=True)'''\n",
    "\n",
    "path_to_store_std_scaler = './ifcb_split_data/std_scaler.bin'\n",
    "os.makedirs('./ifcb_split_data/', exist_ok= True)\n",
    "\n",
    "trainAttrX, valAttrX, testAttrX, trainImagesX, \\\n",
    "    valImagesX, testImagesX, y_train, y_val, y_test = \\\n",
    "    prepare_training_data(df, all_images, min_samples, path_to_store_std_scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac7004cc-f3fe-469f-a0e6-1c0fac910d08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((109, 5),\n",
       " (22, 5),\n",
       " (21, 5),\n",
       " (109, 101, 64, 3),\n",
       " (22, 101, 64, 3),\n",
       " (21, 101, 64, 3),\n",
       " (109, 7),\n",
       " (22, 7),\n",
       " (21, 7))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAttrX.shape, valAttrX.shape, testAttrX.shape, trainImagesX.shape, \\\n",
    "    valImagesX.shape, testImagesX.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc4b6e46-d3bb-4e49-8665-d9185ece9c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the class dictionary, for later use,\n",
    "np.save(path.join('./ifcb_split_data', 'class_dict.npy'),\n",
    "        class_dict,allow_pickle=True)\n",
    "\n",
    "processed_training_data_path=path.join(\"./ifcb_split_data\", \"plankton_data_101x64_final.pkl\")\n",
    "# finally save the training data for future use\n",
    "with open(processed_training_data_path, \"wb\") as f:\n",
    "    pickle.dump((trainAttrX, valAttrX, testAttrX, trainImagesX,\n",
    "                 valImagesX, testImagesX, y_train, y_val, y_test),\n",
    "                f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c54cd-08df-4705-be90-fb783fe5333e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flowcam  Env",
   "language": "python",
   "name": "flwcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
