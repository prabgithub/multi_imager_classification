{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98abb09-eaf7-4574-ae49-7379af1f0026",
   "metadata": {},
   "source": [
    "# Step-4 Notebook for training SVM and MLP models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a5695f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6693409b-f923-4187-9639-73ecf158dae2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the training, validation and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65ce6b0-caa9-4f51-a8fb-802229229320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "processed_training_data_path = \"./flowcam_split_data/plankton_data_101x64_final.pkl\"\n",
    "with open(processed_training_data_path, \"rb\") as file:\n",
    "    trainAttrX, valAttrX, testAttrX, trainImagesX, \\\n",
    "        valImagesX, testImagesX, y_train, y_val, y_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04950dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y=[np.where(r==1)[0][0] for r in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38bfd981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yv=[np.where(r==1)[0][0] for r in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "769eaa1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yt=[np.where(r==1)[0][0] for r in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba938b1-fdf6-4b6e-afb7-772cf0195646",
   "metadata": {},
   "source": [
    "### Load and train SVM model with different kernel types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29016abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(trainAttrX)\n",
    "X_test = scaler.transform(valAttrX)\n",
    "\n",
    "# Initialize the SVM classifier with One-vs-Rest strategy\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42, decision_function_shape='ovr')\n",
    "# svm_rbf_scale = SVC(kernel='rbf', gamma=.3, C=1.0, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Print the accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(yv, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(yv, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6716477f-cf6c-4a7f-93a3-f324020b9637",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save the classification report to results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1bfd194-8684-413c-8cf5-06a2fb4d63cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report_dict = classification_report(yv, y_pred, zero_division=1,output_dict=True)\n",
    "report_df = pd.DataFrame.from_dict(report_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e45d5e0-5d3d-4dcb-83ee-bdf398ff196c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.8/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.8/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be6068f-92a1-4e2c-a840-ff74d5c3dcea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('./results/svc',exist_ok=True)\n",
    "report_df.to_excel(\"./results/svc/val_report_svc_linear.xlsx\")\n",
    "report_df=pd.read_excel(\"./results/svc/val_report_svc_linear.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074bbdb7-6ac4-47f2-b982-183385096af8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yv==y_pred)/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62503157-e55e-45be-b72a-0f64ccffa7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  precision  recall  f1-score  support\n",
       "0             0          1       1         1        6\n",
       "1             1          1       1         1        7\n",
       "2             2          1       1         1        2\n",
       "3             3          1       1         1        8\n",
       "4      accuracy          1       1         1        1\n",
       "5     macro avg          1       1         1       23\n",
       "6  weighted avg          1       1         1       23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f46aac-4a0a-4fbe-a68e-81d513aa7ecc",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f85eacab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.initializers import glorot_uniform, Constant #, HeNormal, Zeros,\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kernel_init = glorot_uniform()\n",
    "bias_init = Constant(value=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b1a21-ddcd-41c9-b273-827804799272",
   "metadata": {},
   "source": [
    "### Define MLP model with path to trained weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5af0efc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(dim: int, num_classes: int, activation: str = \"relu\") -> Model:\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Dense(1024, input_dim=dim, activation=activation, kernel_initializer=kernel_init, bias_initializer=bias_init))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Hidden layers\n",
    "    for _ in range(1):\n",
    "        model.add(Dense(512, activation=activation, kernel_initializer=kernel_init, bias_initializer=bias_init))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    model.build((None, dim))\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_mlp(path_to_split_data,trained_model_folder,epochs=10) -> None:\n",
    "    processed_training_data_path = path_to_split_data\n",
    "    with open(processed_training_data_path, \"rb\") as file:\n",
    "        trainAttrX, valAttrX, testAttrX, trainImagesX, valImagesX, testImagesX, y_train, y_val, y_test = pickle.load(file)\n",
    "\n",
    "    model = multilayer_perceptron(trainAttrX.shape[1], y_train.shape[1])\n",
    "\n",
    "    trained_path = trained_model_folder\n",
    "    os.makedirs(trained_path,exist_ok=True)\n",
    "    output_path = os.path.join(trained_path, \"mlp_model_flowcam_data.h5\")\n",
    "\n",
    "    # Save the best model so far when training\n",
    "    checkpoint = ModelCheckpoint(output_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    # Lower learning rate when models learning has plateaued\n",
    "    lr_drop = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.000001)\n",
    "    # Stop training if signs of model convergence\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=80)\n",
    "    # Enables us to start tensorboard from console for diagnostic tools\n",
    "    # tensor_board = TensorBoard(log_dir='Graph_mlp', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    callbacks_list = [checkpoint, lr_drop, early_stopping]#, tensor_board]\n",
    "\n",
    "    y = [np.where(r == 1)[0][0] for r in y_train]\n",
    "    for v in np.where(~y_train.any(axis=0))[0]:\n",
    "        for _ in range(1000):\n",
    "            y.append(v)\n",
    "    classes = np.unique(y)\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=classes, y=y)\n",
    "    class_weights = dict(zip(classes, class_weights))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(trainAttrX, y_train, epochs=epochs, validation_data=(valAttrX, y_val), callbacks=callbacks_list, batch_size=500, class_weight=class_weights)\n",
    "\n",
    "    # with open(os.path.join(trained_path, \"{}_history\".format(\"mlp\")), 'wb') as file:\n",
    "    #     pickle.dump(history.history, file)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5dc20f-466b-49df-87c3-010a5cc44d8c",
   "metadata": {},
   "source": [
    "### Train the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53b8f7f5-0871-49df-9ab5-6b3fd0b02348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 1024)              45056     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 578,052\n",
      "Trainable params: 574,980\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5801 - accuracy: 0.3814\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91304, saving model to ./trained_models/mlp_model_flowcam_data.h5\n",
      "1/1 [==============================] - 1s 994ms/step - loss: 1.5801 - accuracy: 0.3814 - val_loss: 0.5740 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 2/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9576\n",
      "Epoch 2: val_accuracy did not improve from 0.91304\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1563 - accuracy: 0.9576 - val_loss: 0.3367 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 3/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9746\n",
      "Epoch 3: val_accuracy did not improve from 0.91304\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0903 - accuracy: 0.9746 - val_loss: 0.2534 - val_accuracy: 0.9130 - lr: 0.0010\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9915\n",
      "Epoch 4: val_accuracy did not improve from 0.91304\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0404 - accuracy: 0.9915 - val_loss: 0.2198 - val_accuracy: 0.9130 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Run the training function\n",
    "processed_training_data_path = \"./flowcam_split_data/plankton_data_101x64_final.pkl\"\n",
    "trained_model_folder = \"./trained_models\"\n",
    "hist=train_mlp(processed_training_data_path,trained_model_folder,epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d944b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13570641-36a5-4809-8685-1e7661a19199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca4a70-0576-42c7-b3d7-dddfd16f99d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flowcam  Env",
   "language": "python",
   "name": "flwcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
